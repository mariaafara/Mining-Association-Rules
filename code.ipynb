{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"GrandEst\",sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REGION</th>\n",
       "      <th>NUMMR</th>\n",
       "      <th>ACHLR</th>\n",
       "      <th>AEMM</th>\n",
       "      <th>AEMMR</th>\n",
       "      <th>AGED</th>\n",
       "      <th>AGER20</th>\n",
       "      <th>AGEREV</th>\n",
       "      <th>AGEREVQ</th>\n",
       "      <th>ANAI</th>\n",
       "      <th>...</th>\n",
       "      <th>TP</th>\n",
       "      <th>TRANS</th>\n",
       "      <th>TYPC</th>\n",
       "      <th>TYPFC</th>\n",
       "      <th>TYPL</th>\n",
       "      <th>TYPMD</th>\n",
       "      <th>TYPMR</th>\n",
       "      <th>UR</th>\n",
       "      <th>VOIT</th>\n",
       "      <th>WC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2008</td>\n",
       "      <td>9</td>\n",
       "      <td>58</td>\n",
       "      <td>64</td>\n",
       "      <td>57</td>\n",
       "      <td>55</td>\n",
       "      <td>1959</td>\n",
       "      <td>...</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2008</td>\n",
       "      <td>9</td>\n",
       "      <td>69</td>\n",
       "      <td>79</td>\n",
       "      <td>68</td>\n",
       "      <td>65</td>\n",
       "      <td>1948</td>\n",
       "      <td>...</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1977</td>\n",
       "      <td>6</td>\n",
       "      <td>70</td>\n",
       "      <td>79</td>\n",
       "      <td>69</td>\n",
       "      <td>65</td>\n",
       "      <td>1948</td>\n",
       "      <td>...</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Z</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2012</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>1985</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2012</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>1985</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2014</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>1988</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Z</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>44</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2016</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>...</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>44</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2016</td>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>1991</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>44</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2016</td>\n",
       "      <td>9</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>36</td>\n",
       "      <td>35</td>\n",
       "      <td>1980</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>44</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2012</td>\n",
       "      <td>9</td>\n",
       "      <td>42</td>\n",
       "      <td>54</td>\n",
       "      <td>41</td>\n",
       "      <td>40</td>\n",
       "      <td>1974</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   REGION  NUMMR  ACHLR  AEMM  AEMMR  AGED  AGER20  AGEREV  AGEREVQ  ANAI  \\\n",
       "0      44      1      3  2008      9    58      64      57       55  1959   \n",
       "1      44      1      3  2008      9    69      79      68       65  1948   \n",
       "2      44      2      4  1977      6    70      79      69       65  1948   \n",
       "3      44      3      3  2012      9    30      29      29       25  1985   \n",
       "4      44      3      3  2012      9    30      29      29       25  1985   \n",
       "5      44      4      6  2014      9    30      29      29       25  1988   \n",
       "6      44      5      7  2016      9     1       2       0        0  2016   \n",
       "7      44      5      7  2016      9    26      29      25       25  1991   \n",
       "8      44      5      7  2016      9    37      39      36       35  1980   \n",
       "9      44      6      6  2012      9    42      54      41       40  1974   \n",
       "\n",
       "   ... TP  TRANS  TYPC  TYPFC TYPL  TYPMD TYPMR   UR  VOIT  WC  \n",
       "0  ...  Z      Z   3.0      2  2.0  500.0  44.0  1.0   1.0   Z  \n",
       "1  ...  Z      Z   3.0      2  2.0  500.0  44.0  1.0   1.0   Z  \n",
       "2  ...  Z      Z   1.0      Z  1.0   22.0  12.0  0.0   1.0   Z  \n",
       "3  ...  1      4   3.0      2  2.0  300.0  41.0  0.0   1.0   Z  \n",
       "4  ...  1      4   3.0      2  2.0  300.0  41.0  0.0   1.0   Z  \n",
       "5  ...  1      4   3.0      Z  2.0   11.0  11.0  1.0   1.0   Z  \n",
       "6  ...  Z      Z   2.0      2  1.0  301.0  41.0  1.0   2.0   Z  \n",
       "7  ...  1      4   2.0      2  1.0  301.0  41.0  1.0   2.0   Z  \n",
       "8  ...  1      4   2.0      2  1.0  301.0  41.0  1.0   2.0   Z  \n",
       "9  ...  1      4   3.0      2  2.0  300.0  41.0  1.0   2.0   Z  \n",
       "\n",
       "[10 rows x 97 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An imortant note : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For __INPER__ attribute the values found in the dataset differes from the ones in the signification pdf!!!!\n",
    "Where in the pdf they are Y and Z while in the data set they are numbers!\n",
    "So i considered that the numbers are indication to the number of person in the household\n",
    "<BR>\n",
    "For example 3 indicated the there are 3 people who live in the household"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  1.,  3.,  4.,  6.,  5.,  8.,  7.,  9., 10., 11., 15., 14.,\n",
       "       19., 13., 12., 38., 16., 17., nan])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.INPER.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in df.columns:\n",
    "#     print(i,df[i].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols=[\"AGER20\", \"ANARR\", \"ASCEN\", \"BAIN\",\n",
    "# \"BATI\", \"CATL\", \"CHOS\", \"CLIM\", \"CMBL\", \"COUPLE\", \"CS1\", \"CUIS\", \"DEROU\", \"DIPL_15\", \"EAU\", \"EGOUL\",\n",
    "# \"ELEC\", \"EMPL\", \"ETUD\", \"GARL\", \"ILTUU\", \"IMMI\", \"INAT\", \"INFAM\", \"INPER\", \"MOCO\", \"MODV\", \"NA38\",\n",
    "# \"NATC\", \"NATNC\", \"NBPI\", \"NPERR\", \"RECH\", \"SANI\", \"SEXE\", \"SFM\", \"STOCD\", \"TACT\", \"VOIT\", \"WC\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A 2 dimensional dictionary is created which have as a key, \n",
    "# the attribute name and as a value, another dictionary of \n",
    "# which each key represents a unique value of its key attribute\n",
    "# with a corresponding unique integer as a value in the second dictionary.\n",
    "#at the same time a reverse dictionary is created for decoding use\n",
    "\n",
    "def generate_dic(df,columns):\n",
    "    ind=0\n",
    "    dic_enc={}\n",
    "    dic_dec={}\n",
    "    for column in columns:\n",
    "        for val in df[column].unique():\n",
    "            if(dic_enc.get(column) is None):\n",
    "                dic_enc[column]={}\n",
    "            dic_enc[column][str(val)]=ind\n",
    "            dic_dec[str(ind)]=\"('\"+column+\"', '\"+str(val)+\"')\"\n",
    "            ind+=1\n",
    "    return (dic_enc,dic_dec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder for the DATA SET FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Then for each transaction in the dataset a \n",
    "# mapping was created from the unique items in \n",
    "# the dataset to integers so that each item corresponds \n",
    "# to a unique integer according to the dictionary created.\n",
    "\n",
    "def encode_line(line,dic):\n",
    "    enc=\"\"\n",
    "    for ind,val in line.items():\n",
    "        if enc!=\"\":\n",
    "            enc+=\" \"\n",
    "        enc+=str(dic[ind][str(val)])\n",
    "    return enc\n",
    "\n",
    "\n",
    "def encoder(input_file,columns,output_file,dic_enc):\n",
    "    df=pd.read_csv(input_file,sep=\";\")\n",
    "    f=open(output_file,\"w\")\n",
    "    for _,val in df[columns].iterrows():\n",
    "        f.write(encode_line(val,dic_enc))\n",
    "        f.write(\"\\n\")\n",
    "    f.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder for ITEMSETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################for itemsets#################################\n",
    "\n",
    "def decode_line(line,dic_dec):\n",
    "    decoded_line=\"\"\n",
    "    line_array=line.strip().split(\"#\")\n",
    "    items=line_array[0].strip().split(\" \")\n",
    "    for item in items:\n",
    "        \n",
    "        decoded_line+=dic_dec[item]+\" \"\n",
    "    decoded_line+=str(\"#\"+line_array[1])\n",
    "    return decoded_line\n",
    "\n",
    "def decoder(inputfile,dic,outputfile):\n",
    "    file=open(inputfile, 'r')\n",
    "    lines=file.readlines()\n",
    "   \n",
    "    with open(outputfile, 'w') as f:\n",
    "        for line in lines:\n",
    "            decoded_line=decode_line(line,dic)\n",
    "            print(decoded_line, file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder for ASSOCIATION RULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 35 ==> 13 #SUP: 907668 #CONF: 0.8936299668507417\n",
    "def decode_line_association_rules(line,dic):\n",
    "    decoded_line=\"\"\n",
    "    line_array=line.strip().split(\"#\")\n",
    "    items=line_array[0].strip().split(\"==>\")\n",
    "    for item in items[0].strip().split(\" \"):\n",
    "        decoded_line+=dic_dec[item]+\" \"\n",
    "    decoded_line+=\"==> \"\n",
    "    for item in items[1].strip().split(\" \"):\n",
    "        decoded_line+=dic_dec[item]+\" \"\n",
    "    decoded_line+=str(\"#\"+line_array[1])\n",
    "    decoded_line+=str(\" #\"+line_array[2])\n",
    "\n",
    "    return decoded_line\n",
    "\n",
    "\n",
    "def decoder_association_rules(inputfile,dic,outputfile):\n",
    "    file=open(inputfile, 'r')\n",
    "    lines=file.readlines()\n",
    "   \n",
    "    with open(outputfile, 'w') as f:\n",
    "        for line in lines:\n",
    "            decoded_line=decode_line_association_rules(line,dic)\n",
    "            print(decoded_line, file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting the attributes and generating the dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=[\"AGER20\", \"ANARR\",\"DEROU\" ,\"DIPL_15\", \"EMPL\", \"ETUD\", \"GARL\", \"ILTUU\", \"IMMI\", \"INAT\", \"INFAM\", \"INPER\", \"MODV\",\n",
    "\"NATC\", \"NBPI\", \"NPERR\", \"RECH\", \"SFM\", \"TACT\", \"VOIT\",\"TYPMR\",\"TRANS\",\"PNAI12\", \"CS2\",\"TYPL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_enc,dic_dec=generate_dic(df,cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder(\"GrandEst\",cols,\"results/encoded_dataset.txt\",dic_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoding itemsets for different supports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder('results/encoded_itemsets_minsup30.txt',dic_dec,'results/decoded_itemsets_minsup30.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder('results/encoded_itemsets_minsup40.txt',dic_dec,'results/decoded_itemsets_minsup40.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder('results/encoded_itemsets_minsup60.txt',dic_dec,'results/decoded_itemsets_minsup60.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder('results/encoded_itemsets_minsup50.txt',dic_dec,'results/decoded_itemsets_minsup50.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoding the resulted association rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_association_rules('results/encoded_association_rules_minsup30_confi_80.txt',dic_dec,'results/decoded_association_rules_minsup30_confi_80.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_association_rules('results/encoded_association_rules_minsup60_confi_80.txt',dic_dec,'results/decoded_association_rules_minsup60_confi_80.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_association_rules('results/encoded_association_rules_minsup40_confi_80.txt',dic_dec,'results/decoded_association_rules_minsup40_confi_80.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_association_rules('results/encoded_association_rules_minsup50_confi_80.txt',dic_dec,'results/decoded_association_rules_minsup50_confi_80.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
